{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch computation of UMAP coordinates for individual trials\n",
    "Tim Tyree<br>\n",
    "6.24.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:06.247691Z",
     "start_time": "2021-06-25T05:04:49.128046Z"
    }
   },
   "outputs": [],
   "source": [
    "# #automating the boring stuff may take ~20 seconds to initialize here...\n",
    "from lib.getterdone import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What this notebook does__\n",
    "- give an easy way to loop through to get mass outputs\n",
    "- get the raw xy umap coordinates for individual trials that satisfy a customizable modality/condition\n",
    "\n",
    "__Schema for UMAP results__\n",
    "- phase - integer label of observation (0 for dubious, 1 for decisive, and 2 for reflective)\n",
    "- t - time of observation (seconds) s.t. t=0 corresponds to stimulus start time\n",
    "- x - the x coordinate of umap results\n",
    "- y - the y coordinate of umap results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple interface for selecting which trials/data to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## select a folder that contains input .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:06.263132Z",
     "start_time": "2021-06-25T05:05:06.250041Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please search for a file from within the folder you wish to compute UMAP results for (see pop-up window)...\n",
      "There were 55 trial sets found in data_folder: /Users/timothytyree/Documents/GitHub/neurophysics/notebooks/Data/update-6-5-2021\n"
     ]
    }
   ],
   "source": [
    "use_search_gui=False\n",
    "warnings=True\n",
    "printing=True\n",
    "\n",
    "print(\"Please search for a file from within the folder you wish to compute UMAP results for (see pop-up window)...\")\n",
    "if use_search_gui:\n",
    "    file=search_for_file()\n",
    "else:\n",
    "    #previously selected files\n",
    "    file=\"/Users/timothytyree/Documents/GitHub/neurophysics/notebooks/Data/update-6-5-2021/Archie_SRT_Set211_Subset1_200518_130717_trialData.csv\"\n",
    "\n",
    "file_lst=get_all_files_matching_pattern(file,'.csv')\n",
    "data_folder=os.path.dirname(file)\n",
    "os.chdir(data_folder)\n",
    "#compute the set of all modnames in data_folder\n",
    "modname_lst=sorted(set([parse_for_modname(file) for file in file_lst]))\n",
    "print(f\"There were {len(modname_lst)} trial sets found in data_folder: {data_folder}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## (optional) import a token trial set from that folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:12.130935Z",
     "start_time": "2021-06-25T05:05:06.265662Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files were found for trial set: Archie_SRT_Set212_Subset1_200520_165716_.\n"
     ]
    }
   ],
   "source": [
    "#load a single set of trials into notebook memory\n",
    "j=2\n",
    "modname=modname_lst[j]\n",
    "t_min_considered, number_of_neurons, dict_spike_times, dict_trial_times, dict_trial_data = load_dataset(modname,data_folder,\n",
    "                                                                                                        warnings=warnings,\n",
    "                                                                                                       printing=printing)\n",
    "boo_all_files_found=determine_whether_all_files_were_found(t_min_considered, number_of_neurons, dict_spike_times, dict_trial_times, dict_trial_data)\n",
    "if boo_all_files_found:\n",
    "    if printing:\n",
    "        print(f'All files were found for trial set: {modname}.')\n",
    "    setnum=parse_set_number(modname)\n",
    "else:\n",
    "    if printing:\n",
    "        print(f'Warning: not all files were found for trial set: {modname}. Consider a different j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:12.205453Z",
     "start_time": "2021-06-25T05:05:12.133761Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imName</th>\n",
       "      <th>imNum</th>\n",
       "      <th>imPheeName</th>\n",
       "      <th>imMatchFlag</th>\n",
       "      <th>novel</th>\n",
       "      <th>imOff</th>\n",
       "      <th>vpltTrial</th>\n",
       "      <th>Block</th>\n",
       "      <th>PheeID</th>\n",
       "      <th>PicID_1</th>\n",
       "      <th>PicID_2</th>\n",
       "      <th>PidID_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JennyRightGood3.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5081116752699</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>jenny</td>\n",
       "      <td>Right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChewieRightGood1.JPG</td>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50763143645599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>chewie</td>\n",
       "      <td>Right</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HermesFrontGood2.JPG</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50854450464249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>hermes</td>\n",
       "      <td>Front</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HankRightGood1.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>hank</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.66679767635651</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>hank</td>\n",
       "      <td>hank</td>\n",
       "      <td>Right</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HermesFrontGood2.JPG</td>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50858635362238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>hermes</td>\n",
       "      <td>Front</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 imName imNum imPheeName imMatchFlag novel             imOff  \\\n",
       "1   JennyRightGood3.JPG     2       none           0     1   3.5081116752699   \n",
       "2  ChewieRightGood1.JPG     3       none           0     1  3.50763143645599   \n",
       "3  HermesFrontGood2.JPG     4       none           0     1  3.50854450464249   \n",
       "4    HankRightGood1.jpg     5       hank           1     1  2.66679767635651   \n",
       "5  HermesFrontGood2.JPG     4       none           0     0  3.50858635362238   \n",
       "\n",
       "  vpltTrial Block PheeID PicID_1 PicID_2 PidID_3  \n",
       "1         1     1   none   jenny   Right       2  \n",
       "2         1     1   none  chewie   Right       3  \n",
       "3         1     1   none  hermes   Front       4  \n",
       "4         1     1   hank    hank   Right       5  \n",
       "5         1     1   none  hermes   Front       4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data for one trial and view an example pandas.Dataframe from 1 set\n",
    "df = pd.DataFrame(dict_trial_data).T\n",
    "df['PicID_1'] = [s.lower() for s in df['PicID_1'].values]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:12.211984Z",
     "start_time": "2021-06-25T05:05:12.207472Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#get querying options that are availble in the current trial set \n",
    "# PicID_1_lst=sorted(set(df.PicID_1.values))\n",
    "PheeID_lst=sorted(set(df.PheeID.values))\n",
    "orientation_lst=sorted(set(df.PicID_2.values))\n",
    "imname_lst=sorted(set(df.imName.values))\n",
    "\n",
    "# #print which options were found\n",
    "# print(orientation_lst)\n",
    "# print(sorted(set(df.imPheeName.values)))\n",
    "# print(imname_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T23:05:24.313034Z",
     "start_time": "2021-06-24T23:05:24.290241Z"
    }
   },
   "source": [
    "## define a function that selects which trials to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example,\n",
    "\n",
    "```imMatchFlag=1\n",
    "vpltTrial=1  # as stimulus was presented\n",
    "output_folder=f'selecting_imMatchFlag_{imMatchFlag}'\n",
    "def my_query_function(df):\n",
    "    boo =(df.vpltTrial==vpltTrial)\n",
    "    boo&=df.imMatchFlag==imMatchFlag\n",
    "    return boo```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you may define a custom my_query_function that takes a pandas.Dataframe of your trial set as input and returns a boolean index, `boo` that is `True` for any trial that you want to compute UMAP results for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:12.219269Z",
     "start_time": "2021-06-25T05:05:12.214708Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Examples of my_query_function\n",
    "#################################\n",
    "imMatchFlag=1\n",
    "vpltTrial=1  # as stimulus was presented\n",
    "output_folder=f'selecting_imMatchFlag_{imMatchFlag}'\n",
    "def my_query_function(df):\n",
    "    boo =(df.vpltTrial==vpltTrial)\n",
    "    boo&=df.imMatchFlag==imMatchFlag\n",
    "    return boo\n",
    "\n",
    "# output_folder='selecting_alltrials'\n",
    "# def my_query_function(df):\n",
    "#     '''selects every trial'''\n",
    "#     return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:12.234236Z",
     "start_time": "2021-06-25T05:05:12.225074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_folder: selecting_imMatchFlag_1\n",
      "trials matching query for trial set 212 only: [4, 8, 12, 16, 18, 23, 25, 31, 36, 38, 45, 68, 69, 70, 71, 72, 73, 82, 84, 106, 113, 121, 127, 131, 140, 143, 145, 149, 166, 170, 174, 175, 181, 187, 190, 195, 199, 203, 204, 207, 208, 237, 238, 239, 240, 241, 246, 252, 260, 263, 264, 265, 288, 292, 294, 298, 302, 304, 306, 309, 313, 319, 342, 346, 348, 352, 354, 377, 379, 381, 382, 384, 386, 388, 389, 391, 392, 397, 398, 412, 417, 432, 443, 444]\n",
      "blocks matching query for trial set 212 only: [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26]\n"
     ]
    }
   ],
   "source": [
    "#perform a query to identify the trials to be considered from this trial set\n",
    "boo=my_query_function(df)\n",
    "trialnum_include_values=df[boo].index.values\n",
    "\n",
    "block_lst=sorted(set(df[boo].Block.values))\n",
    "setnum=parse_set_number(modname)\n",
    "if printing:\n",
    "    print(f\"output_folder: {output_folder}\")\n",
    "    print(f\"trials matching query for trial set {setnum} only: {sorted(trialnum_include_values)}\")\n",
    "    print(f\"blocks matching query for trial set {setnum} only: {block_lst}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## (optional) additional examples for my_query_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:12.244341Z",
     "start_time": "2021-06-25T05:05:12.239754Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# output_folder='selecting_copper'\n",
    "# def my_query_function(df):\n",
    "#     '''Query function that selects a given monkey, where a stimulus is presented.'''\n",
    "#     #choose constant values\n",
    "#     vpltTrial=1  # as stimulus was presented\n",
    "#     # monkname=PheeID_lst[4]\n",
    "#     # monkname=PheeID_lst[3]#cooper\n",
    "#     monkname='copper'\n",
    "#     # orientation='Front'#'none'\n",
    "#     #select trials of relevance\n",
    "#     boo=df.vpltTrial==vpltTrial\n",
    "#     boo&=df.imPheeName==monkname #may be redundant\n",
    "#     boo&=df.PheeID==monkname     #may be redundant\n",
    "#     # boo&=df.orientation==orientation \n",
    "#     return boo\n",
    "\n",
    "# imMatchFlag=3\n",
    "# output_folder=f'selecting_imMatchFlag_{imMatchFlag}'\n",
    "# def my_query_function(df):\n",
    "#     vpltTrial=1  # as stimulus was presented\n",
    "#     monkname_lst=[\n",
    "# #         'aladdin',\n",
    "# #          'ares',\n",
    "# #          'chewie',\n",
    "# #          'copper',\n",
    "# #          'dip',\n",
    "# #          'han',\n",
    "# #          'hank',\n",
    "# #          'hermes',\n",
    "# #          'jasmine',\n",
    "#          'mowgli',\n",
    "#          'none',\n",
    "# #          'poseidon',\n",
    "# #          'raja',\n",
    "# #          'waylon'\n",
    "#     ]\n",
    "#     boo =False&(df.vpltTrial==1)\n",
    "#     for monkname in monkname_lst:\n",
    "#         boo|=df.imPheeName==monkname #may be redundant\n",
    "#         boo|=df.PheeID==monkname     #may be redundant\n",
    "#     boo&=(df.vpltTrial==1)\n",
    "#     boo&=df.imMatchFlag==imMatchFlag\n",
    "#     return boo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute and save umap xy coordinates for individual trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:12.268033Z",
     "start_time": "2021-06-25T05:05:12.247378Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_routine(output_folder,data_folder):\n",
    "    def routine(modname):\n",
    "        '''\n",
    "        routine computes umap xy coordinates for each trial in the trial set indicated by modname located in data_folder.\n",
    "        trials are only considered if selected by my_query_function.\n",
    "        saves umap xy coordinates for each trial as a .csv file in the folder, output_folder.\n",
    "        returns a list of lists of output .csv directories\n",
    "        '''\n",
    "        ################################\n",
    "        # Modify Routine Parameters Here\n",
    "        ################################\n",
    "        #parameters you might be interested in changing\n",
    "        t_arrival=1.5 #seconds\n",
    "        t_departure=2.5 #seconds\n",
    "        t_arrival_physical=.15 #seconds\n",
    "        t_stop=3. #seconds\n",
    "        umap_kwargs={\n",
    "            'metric'      :'cosine',#'correlation',\n",
    "            'random_state':42, # for random_state fixed, the umap results are repeatable to machine precision \n",
    "        #     'min_dist'    :0.5,\n",
    "        #     'spread'      :2\n",
    "        }\n",
    "        output_metric='hyperbolic'\n",
    "        # output_metric='gaussian'\n",
    "        \n",
    "        #parameters I don't think you'll be interested in changing\n",
    "        use_cache0=True\n",
    "        nid_self=None #automatically select the most spiking neuron to be nid_self\n",
    "        # nid_self=12 #set nid_self to the 13th neuron. #nid_self decides time points to take observations as spike times of some neuron\n",
    "        warnings=False\n",
    "        printing=False\n",
    "        min_num_obs=1 #the minimum number of spikes nid_self needs to have for this trial to be considered\n",
    "        cache_folder=data_folder+'/cache/'\n",
    "        \n",
    "        ################################\n",
    "        # Main Routine\n",
    "        ################################\n",
    "        os.chdir(data_folder)\n",
    "        #load a single set of trials into notebook memory\n",
    "        t_min_considered, number_of_neurons, dict_spike_times, dict_trial_times, dict_trial_data = load_dataset(modname,data_folder,warnings=warnings,printing=printing)\n",
    "        boo_all_files_found=determine_whether_all_files_were_found(t_min_considered, number_of_neurons, dict_spike_times, dict_trial_times, dict_trial_data)\n",
    "        if not boo_all_files_found:\n",
    "            if printing:\n",
    "                print(f'Warning: not all files were found for trial set: {modname}.')\n",
    "            return None\n",
    "\n",
    "        #determine which trial to consider using my_query_function\n",
    "        df = pd.DataFrame(dict_trial_data).T\n",
    "        df['PicID_1'] = [s.lower() for s in df['PicID_1'].values]\n",
    "        boo=my_query_function(df)\n",
    "        trialnum_include_values=df[boo].index.values\n",
    "\n",
    "        \n",
    "        output_dir_lst=[]\n",
    "        # loop over all trials\n",
    "        for trialnum in trialnum_include_values:\n",
    "            trial_kwargs=dict(df.loc[trialnum])\n",
    "            output_modname=return_output_modname(modname,trialnum,trial_kwargs,\n",
    "                                                 make_output_self_documenting=True)\n",
    "            output_fn=output_modname+f'_nid_self_{nid_self}.csv'\n",
    "            output_dir=os.path.join(output_folder,output_fn)\n",
    "\n",
    "            #identify the neuron with the most spikes as nid_self\n",
    "            nid_self=0\n",
    "            max_obs=0\n",
    "            for nid in range(number_of_neurons):\n",
    "                obs=dict_spike_times[nid].shape[0]\n",
    "                if obs>max_obs:\n",
    "                    max_obs=obs\n",
    "                    nid_self=nid\n",
    "            \n",
    "            if nid_self is not None:\n",
    "                save_fn=modname+f'compressedPointProcess_nid_self_{nid_self}.npz'\n",
    "            else:\n",
    "                save_fn='none'\n",
    "                \n",
    "            os.chdir(data_folder)\n",
    "            os.chdir(cache_folder)\n",
    "            #compute the point process and cache in save_fn\n",
    "            if (not os.path.exists(save_fn)) or (not use_cache0):\n",
    "                #compute the point process model\n",
    "                nid_self,target,data,trialnum_values,t_values=compute_point_process_data(t_min_considered, number_of_neurons, \n",
    "                                                                                         dict_spike_times, dict_trial_times,\n",
    "                                                                                         dict_trial_data,\n",
    "                                                                                         printing=printing,\n",
    "                                                                                         nid_self=nid_self,\n",
    "                                                                                         t_arrival=t_arrival,\n",
    "                                                                                         t_departure=t_departure,\n",
    "                                                                                         t_arrival_physical=t_arrival_physical,\n",
    "                                                                                         t_stop=t_stop)\n",
    "\n",
    "                #change directories to cache location\n",
    "                os.chdir(data_folder)\n",
    "                os.chdir(cache_folder)\n",
    "                #cache the resulting point process as a compressed numpy array for later reuse\n",
    "                save_fn=modname+f'pointProcess_{nid_self}_compressed.npz'\n",
    "                np.savez_compressed(save_fn, target=target,data=data,trialnum_values=trialnum_values,t_values=t_values)\n",
    "                if printing:\n",
    "                    print(f'For nid_self={nid_self}, the resulting pointprocess was saved in: \\n\\t{save_fn}')\n",
    "\n",
    "            #load the point process from cache\n",
    "            cached_fn=os.path.abspath(save_fn)\n",
    "            dataset=np.load(save_fn)\n",
    "            #extract lag feature vector\n",
    "            data=dataset['data']\n",
    "            target=dataset['target']\n",
    "            trialnum_values=dataset['trialnum_values']\n",
    "            spike_times=dataset['t_values']\n",
    "            target_names=[r'dubious',r'decisive',r'reflective']\n",
    "\n",
    "            #query trials by trial\n",
    "            # match=True\n",
    "            # mismatch=False\n",
    "            # novel=False\n",
    "            query=trialnum_values==trialnum\n",
    "            dat=data[query,:]\n",
    "            targ=target[query]\n",
    "            t_values_out=t_values[query]\n",
    "            num_obs=dat.shape[0]\n",
    "\n",
    "            if num_obs>=min_num_obs:\n",
    "                # if printing:\n",
    "                #     print(f\"fitting umap to the {num_obs} observations considered in this trial...\")\n",
    "                #TODO: compute umap xy coordinates, \n",
    "                if output_metric == 'hyperbolic':\n",
    "                    x_values,y_values = get_hyperbolic_umap_xycoordinates(dat,**umap_kwargs) #computes the underlying class instance and returns the xy values for each observation\n",
    "                elif output_metric == 'gaussian':\n",
    "                    x_values,y_values = get_gaussian_umap_xycoordinates(dat,**umap_kwargs) #computes the underlying class instance and returns the xy values for each observation\n",
    "\n",
    "                # save umap coordinates to .csv\n",
    "                successfully_saved_bool=save_umap_xycoords_to_csv(output_dir,x_values,y_values,targ,t_values_out)\n",
    "                output_dir_lst.append (output_dir)\n",
    "\n",
    "        return output_dir_lst\n",
    "    return routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:12.279022Z",
     "start_time": "2021-06-25T05:05:12.271369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cores found: 8\n"
     ]
    }
   ],
   "source": [
    "#define function for the main routine\n",
    "npartitions=os.cpu_count()\n",
    "output_folder=os.path.abspath(output_folder)\n",
    "print(f'number of cores found: {npartitions}')\n",
    "\n",
    "#initialize output_folder if it doesn't already exist\n",
    "os.chdir(data_folder)\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "os.chdir(output_folder)\n",
    "#initialize cache_folder if it doesn't already exist\n",
    "os.chdir(data_folder)\n",
    "cache_folder=data_folder+'/cache/'\n",
    "if not os.path.exists(cache_folder):\n",
    "    os.mkdir(cache_folder)\n",
    "\n",
    "routine=get_routine(output_folder,data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T05:05:18.233750Z",
     "start_time": "2021-06-25T05:05:12.282382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test importing of trial set data. stdout should read True\n",
    "t_min_considered, number_of_neurons, dict_spike_times, dict_trial_times, dict_trial_data = load_dataset(modname,data_folder,warnings=warnings,printing=printing)\n",
    "boo_all_files_found=determine_whether_all_files_were_found(t_min_considered, number_of_neurons, dict_spike_times, dict_trial_times, dict_trial_data)\n",
    "boo_all_files_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.005Z"
    }
   },
   "outputs": [],
   "source": [
    "# #test the routine. stdout should be a list of file names\n",
    "# routine(modname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:12:17.813Z"
    }
   },
   "outputs": [],
   "source": [
    "# #test for smaller runtimes because of autocaching caching is nonzero routine. stdout should be a list of file names\n",
    "# routine(modname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.008Z"
    }
   },
   "outputs": [],
   "source": [
    "#for each trial set...\n",
    "bag = db.from_sequence(modname_lst, npartitions=npartitions).map(routine)\n",
    "print(f\"saving xy coordinates for the trials satistfying my_query_function.\\nlooking in {len(retval_lst)} trial sets.\\noutputing to .csv in output_folder={output_folder}...\")\n",
    "start = time.time()\n",
    "retval_lst = list(bag)\n",
    "print(f\"the run time for computing umap individual xy coordinates was {(time.time()-start)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.011Z"
    }
   },
   "outputs": [],
   "source": [
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.012Z"
    }
   },
   "outputs": [],
   "source": [
    "#look at all the xy coordinates you just made!\n",
    "os.chdir(output_folder)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.014Z"
    }
   },
   "outputs": [],
   "source": [
    "retval_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T02:09:10.723921Z",
     "start_time": "2021-06-25T02:09:10.719180Z"
    }
   },
   "source": [
    "# plot UMAP xy coordinates for a given trial in a given trial set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.018Z"
    }
   },
   "outputs": [],
   "source": [
    "modnum=2\n",
    "trialnum=4\n",
    "modname=modname_lst[modnum]\n",
    "\n",
    "# compute a umap fit for the point process sampled from a trial given by trialnum\n",
    "t_min_considered, number_of_neurons, dict_spike_times, dict_trial_times, dict_trial_data = load_dataset(modname,data_folder,\n",
    "                                                                                                        warnings=warnings,\n",
    "                                                                                                       printing=printing)\n",
    "#determine which trial to consider using my_query_function\n",
    "df = pd.DataFrame(dict_trial_data).T\n",
    "df['PicID_1'] = [s.lower() for s in df['PicID_1'].values]\n",
    "boo=my_query_function(df)\n",
    "trialnum_include_values=df[boo].index.values\n",
    "nid_self=None\n",
    "\n",
    "nid_self,target,data,trialnum_values,t_values=compute_point_process_data(t_min_considered, number_of_neurons, \n",
    "                                                                                     dict_spike_times, dict_trial_times,\n",
    "                                                                                     dict_trial_data,\n",
    "                                                                                     printing=printing,\n",
    "                                                                                     nid_self=nid_self,\n",
    "                                                                                     t_arrival=t_arrival,\n",
    "                                                                                     t_departure=t_departure,\n",
    "                                                                                     t_arrival_physical=t_arrival_physical,\n",
    "                                                                                     t_stop=t_stop)\n",
    "query=trialnum_values==trialnum\n",
    "\n",
    "#query by computing the boolean index for a given condition\n",
    "dat=data[query,:]\n",
    "targ=target[query]\n",
    "t_values_out=t_values[query]\n",
    "num_obs=dat.shape[0]\n",
    "#define color values\n",
    "c_values=targ\n",
    "\n",
    "umap_kwargs={\n",
    "    'metric'      :'cosine',#'correlation',\n",
    "    'random_state':42, # for random_state fixed, the umap results are repeatable to machine precision \n",
    "#     'min_dist'    :0.5,\n",
    "#     'spread'      :2\n",
    "}\n",
    "\n",
    "print(f\"fitting umap to the {num_obs} observations considered in this trial...\")\n",
    "output_metric='hyperbolic'\n",
    "if output_metric == 'hyperbolic':\n",
    "    # gaussian_mapper=fit_gaussian_mapper(data,**kwargs) #returns the underlying class instance\n",
    "    x_values,y_values = get_hyperbolic_umap_xycoordinates(dat,**umap_kwargs) #computes the underlying class instance and returns the xy values for each observation\n",
    "\n",
    "print(f\"plotting 2D projections...\")   \n",
    "print(f\"...these plots can be saved using the function, fig.savefig.\")   \n",
    "fig=PlotUmapCoordsHyperbolic(x_values,y_values,c_values)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.020Z"
    }
   },
   "outputs": [],
   "source": [
    "# saves umap coordinates to .csv\n",
    "trial_kwargs=dict(df.loc[trialnum])\n",
    "output_modname=return_output_modname(modname,trialnum,trial_kwargs,\n",
    "                                     make_output_self_documenting=True)\n",
    "output_fn=output_modname+'.csv'\n",
    "output_dir=os.path.join(data_folder,output_folder,output_fn)\n",
    "\n",
    "output_dir=os.path.join(data_folder,output_folder,output_fn)\n",
    "successfully_saved_bool=save_umap_xycoords_to_csv(output_dir,x_values,y_values,targ,t_values_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.021Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_search_gui:\n",
    "    input_dir=search_for_file()\n",
    "else:\n",
    "    input_dir=output_dir\n",
    "#load a given umap xycoordinate csv file for the hyperbolic embedding\n",
    "x_values,y_values,targ,t_values_out=load_umap_xycoords_from_csv(input_dir)\n",
    "fig=PlotUmapCoordsHyperbolic(x_values,y_values,c_values)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.023Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute a umap fit for the point process sampled from each trial\n",
    "output_metric='gaussian'\n",
    "if output_metric == 'gaussian':\n",
    "    # gaussian_mapper=fit_gaussian_mapper(data,**kwargs) #returns the underlying class instance\n",
    "    x_values,y_values = get_gaussian_umap_xycoordinates(dat,**umap_kwargs) #computes the underlying class instance and returns the xy values for each observation\n",
    "           \n",
    "fig=PlotUmapCoordsGaussian(x_values,y_values,c_values)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-25T05:04:49.024Z"
    }
   },
   "outputs": [],
   "source": [
    "print('all jobs completed successfully!')\n",
    "beep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T02:09:20.284486Z",
     "start_time": "2021-06-25T02:09:20.279706Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T02:09:20.292813Z",
     "start_time": "2021-06-25T02:09:20.289405Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
